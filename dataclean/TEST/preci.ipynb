{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse the QREL file\n",
    "def parse_qrels(qrels_file):\n",
    "    qrels = {}\n",
    "    with open(qrels_file, 'r') as file:\n",
    "        for line in file:\n",
    "            topicId, _, docId, relevance = line.split()\n",
    "            relevance = int(relevance)\n",
    "            if topicId not in qrels:\n",
    "                qrels[topicId] = {}\n",
    "            qrels[topicId][docId] = relevance\n",
    "    return qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate precision at k\n",
    "def precision_at_k(relevant, retrieved, k):\n",
    "    retrieved_at_k = retrieved[:k]\n",
    "    true_positives = sum([1 for docId in retrieved_at_k if docId in relevant])\n",
    "    return true_positives / k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate average precision at k\n",
    "def average_precision(relevant, retrieved, k):\n",
    "    precisions = [precision_at_k(relevant, retrieved, i + 1) for i in range(k) if retrieved[i] in relevant]\n",
    "    if not precisions:\n",
    "        return 0.0\n",
    "    return sum(precisions) / len(precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate P@10 and MAP@10\n",
    "def calculate_metrics(df, qrels, k=10):\n",
    "    p_at_10 = []\n",
    "    ap_at_10 = []\n",
    "    grouped = df.groupby('topicId')\n",
    "    \n",
    "    for topicId, group in grouped:\n",
    "        relevant_docs = qrels.get(topicId, {})\n",
    "        retrieved_docs = group.sort_values('ranking')['docId'].tolist()\n",
    "        p_at_10.append((topicId, precision_at_k(relevant_docs, retrieved_docs, k)))\n",
    "        ap_at_10.append((topicId, average_precision(relevant_docs, retrieved_docs, k)))\n",
    "    \n",
    "    return p_at_10, ap_at_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "qrel_file_path = 'D:\\VSCODE PROJECT\\IR\\dataset\\qrels.trec8.adhoc'\n",
    "input_dir = 'D:\\VSCODE PROJECT\\IR\\cleaned'\n",
    "output_dir = 'D:\\VSCODE PROJECT\\IR\\scores'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the QREL file\n",
    "qrels = parse_qrels(qrel_file_path)\n",
    "\n",
    "# Get the list of input files\n",
    "input_files = [os.path.join(input_dir, file) for file in os.listdir(input_dir) if file.endswith('.txt')]\n",
    "\n",
    "# Initialize a DataFrame to store all results\n",
    "all_results = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each input file\n",
    "for file in input_files:\n",
    "    # Read the input dataset\n",
    "    input_df = pd.read_csv(file, delimiter='\\t', names=['topicId', 'identifier', 'docId', 'ranking', 'similarityScore', 'systemName'])\n",
    "    \n",
    "    # Calculate P@10 and AP@10\n",
    "    p_at_10, ap_at_10 = calculate_metrics(input_df, qrels)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    p_at_10_df = pd.DataFrame(p_at_10, columns=['topicId', 'P@10'])\n",
    "    ap_at_10_df = pd.DataFrame(ap_at_10, columns=['topicId', 'AP@10'])\n",
    "    \n",
    "    # Merge results\n",
    "    results_df = pd.merge(p_at_10_df, ap_at_10_df, on='topicId')\n",
    "    results_df['systemName'] = os.path.basename(file).split('.')[0]\n",
    "    \n",
    "    # Append to all results\n",
    "    all_results = pd.concat([all_results, results_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final results to a file\n",
    "output_path = os.path.join(output_dir, 'scores.csv')\n",
    "all_results.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    topicId  P@10  AP@10     systemName\n",
      "0       401   0.0    0.0  input_ric8dpn\n",
      "1       402   0.0    0.0  input_ric8dpn\n",
      "2       403   0.0    0.0  input_ric8dpn\n",
      "3       404   0.0    0.0  input_ric8dpn\n",
      "4       405   0.0    0.0  input_ric8dpn\n",
      "..      ...   ...    ...            ...\n",
      "45      446   0.0    0.0        plt8ah2\n",
      "46      447   0.0    0.0        plt8ah2\n",
      "47      448   0.0    0.0        plt8ah2\n",
      "48      449   0.0    0.0        plt8ah2\n",
      "49      450   0.0    0.0        plt8ah2\n",
      "\n",
      "[250 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display the final results\n",
    "print(all_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
