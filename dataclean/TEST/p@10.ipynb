{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: D:\\VSCODE PROJECT\\IR\\cleaned_dataset\\cleaned_input.1.1.txt\n",
      "   topicId  Q0             docId  ranking  similarityScore  system\n",
      "0      401  Q0       FBIS4-20472        1              320       1\n",
      "1      401  Q0       FBIS4-68893        2              251       1\n",
      "2      401  Q0  FR941117-2-00158        3              221       1\n",
      "3      401  Q0       FBIS3-37947        4              203       1\n",
      "4      401  Q0          FBIS4-29        5              186       1\n",
      "Processing file: D:\\VSCODE PROJECT\\IR\\cleaned_dataset\\cleaned_input.ok8amxc.txt\n",
      "   topicId  Q0        docId  ranking  similarityScore   system\n",
      "0      401  Q0  FBIS4-18182        1          3.59032  ok8amxc\n",
      "1      401  Q0  FBIS3-18916        2          3.44936  ok8amxc\n",
      "2      401  Q0  FBIS3-18833        3          3.40886  ok8amxc\n",
      "3      401  Q0  FBIS3-39117        4          3.25332  ok8amxc\n",
      "4      401  Q0  FBIS3-17077        5          3.15430  ok8amxc\n",
      "Processing file: D:\\VSCODE PROJECT\\IR\\cleaned_dataset\\cleaned_input.pir9Aa1.txt\n",
      "   topicId  Q0        docId  ranking  similarityScore   system\n",
      "0      401  Q0   FBIS4-9582        1           4.1810  pir9Aa1\n",
      "1      401  Q0  FBIS4-31715        2           4.0127  pir9Aa1\n",
      "2      401  Q0  FT942-15501        3           3.4143  pir9Aa1\n",
      "3      401  Q0   FBIS3-4201        4           3.3311  pir9Aa1\n",
      "4      401  Q0  FBIS4-18182        5           3.3238  pir9Aa1\n",
      "Processing file: D:\\VSCODE PROJECT\\IR\\cleaned_dataset\\cleaned_input.plt8ah2.txt\n",
      "   topicId  Q0        docId  ranking  similarityScore   system\n",
      "0      401  Q0   FBIS4-9582        1        13.814581  plt8ah2\n",
      "1      401  Q0  FT932-10861        2        13.342205  plt8ah2\n",
      "2      401  Q0  FBIS4-18182        3        12.389992  plt8ah2\n",
      "3      401  Q0   FBIS3-9104        4        12.071641  plt8ah2\n",
      "4      401  Q0  FT941-15167        5        11.571873  plt8ah2\n",
      "Processing file: D:\\VSCODE PROJECT\\IR\\cleaned_dataset\\cleaned_input.ric8dpn.txt\n",
      "   topicId  Q0          docId  ranking  similarityScore   system\n",
      "0      401  Q0  LA052590-0090        1         0.518393  ric8dpn\n",
      "1      401  Q0    FBIS3-19951        2         0.447785  ric8dpn\n",
      "2      401  Q0    FBIS3-59436        3         0.439529  ric8dpn\n",
      "3      401  Q0    FBIS4-68774        4         0.434339  ric8dpn\n",
      "4      401  Q0     FBIS4-9582        5         0.424880  ric8dpn\n",
      "Processing file: D:\\VSCODE PROJECT\\IR\\cleaned_dataset\\cleaned_input.UB99T.txt\n",
      "   topicId  Q0        docId  ranking  similarityScore system\n",
      "0      401  Q0  FBIS4-25684        1         177.0670  UB99T\n",
      "1      401  Q0  FBIS4-22981        2         139.5210  UB99T\n",
      "2      401  Q0  FBIS4-68773        3         120.6760  UB99T\n",
      "3      401  Q0  FBIS3-61091        4         110.9000  UB99T\n",
      "4      401  Q0   FT941-3931        5          85.2391  UB99T\n",
      "   topicId  P@10  AP@10         system\n",
      "0      401   0.9    1.0  cleaned_input\n",
      "1      402   0.9    1.0  cleaned_input\n",
      "2      403   0.9    1.0  cleaned_input\n",
      "3      404   0.9    1.0  cleaned_input\n",
      "4      405   0.9    1.0  cleaned_input\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to your dataset directory\n",
    "data_dir = 'D:\\VSCODE PROJECT\\IR\\cleaned_dataset'\n",
    "\n",
    "# Get the list of files in the directory\n",
    "files = [os.path.join(data_dir, file) for file in os.listdir(data_dir) if file.endswith('.txt')]\n",
    "\n",
    "# Define a threshold for similarityScore to determine relevance\n",
    "similarity_threshold = 0.5  # Adjust this value as needed\n",
    "\n",
    "# Define the function to calculate P@10 and AP@10\n",
    "def calculate_p10_ap10(df):\n",
    "    # Filter top 10 documents for each topic\n",
    "    top_10_docs = df[df['ranking'] < 10]\n",
    "    \n",
    "    # Calculate P@10 for each topic\n",
    "    p_at_10 = top_10_docs.groupby('topicId')['relevance'].apply(lambda x: x.sum() / 10)\n",
    "    \n",
    "    # Calculate AP@10 for each topic\n",
    "    def average_precision_at_10(group):\n",
    "        relevant = group['relevance'].values\n",
    "        precisions = [relevant[:i+1].sum() / (i+1) for i in range(len(relevant))]\n",
    "        return sum(precisions) / min(len(relevant), 10)\n",
    "    \n",
    "    ap_at_10 = top_10_docs.groupby('topicId').apply(average_precision_at_10)\n",
    "    \n",
    "    return p_at_10, ap_at_10\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Process each file\n",
    "for file in files:\n",
    "    try:\n",
    "        # Read the dataset\n",
    "        df = pd.read_csv(file, delimiter='\\t', names=['topicId', 'Q0', 'docId', 'ranking', 'similarityScore', 'system'])\n",
    "        \n",
    "        # Debug: Print the first few rows of the dataframe\n",
    "        print(f\"Processing file: {file}\")\n",
    "        print(df.head())\n",
    "        \n",
    "        # Ensure ranking is sorted\n",
    "        df = df.sort_values(by=['topicId', 'ranking'])\n",
    "        \n",
    "        # Create the 'relevance' column based on the similarity threshold\n",
    "        df['relevance'] = (df['similarityScore'] > similarity_threshold).astype(int)\n",
    "        \n",
    "        # Calculate P@10 and AP@10\n",
    "        p_at_10, ap_at_10 = calculate_p10_ap10(df)\n",
    "        \n",
    "        # Append the results with the system name\n",
    "        system_name = os.path.basename(file).split('.')[0]\n",
    "        result_df = pd.DataFrame({\n",
    "            'topicId': p_at_10.index,\n",
    "            'P@10': p_at_10.values,\n",
    "            'AP@10': ap_at_10.values,\n",
    "            'system': system_name\n",
    "        })\n",
    "        \n",
    "        results.append(result_df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "# Concatenate all results into a single DataFrame\n",
    "if results:\n",
    "    final_results = pd.concat(results, ignore_index=True)\n",
    "    # Debug: Print the final results\n",
    "    print(final_results.head())\n",
    "else:\n",
    "    print(\"No valid data found to concatenate.\")\n",
    "\n",
    "# Save the final results to a file\n",
    "output_dir = 'D:\\VSCODE PROJECT\\IR\\scores'\n",
    "os.makedirs(output_dir, exist_ok=True)  # Ensure the directory exists\n",
    "output_path = os.path.join(output_dir, 'p_at_10_scores.csv')\n",
    "if not final_results.empty:\n",
    "    final_results.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: D:\\VSCODE PROJECT\\IR\\cleaned_dataset\\cleaned_input.1.1.txt\n",
      "   topicId  Q0             docId  ranking  similarityScore  system\n",
      "0      401  Q0       FBIS4-20472        1              320       1\n",
      "1      401  Q0       FBIS4-68893        2              251       1\n",
      "2      401  Q0  FR941117-2-00158        3              221       1\n",
      "3      401  Q0       FBIS3-37947        4              203       1\n",
      "4      401  Q0          FBIS4-29        5              186       1\n",
      "Processing file: D:\\VSCODE PROJECT\\IR\\cleaned_dataset\\cleaned_input.ok8amxc.txt\n",
      "   topicId  Q0        docId  ranking  similarityScore   system\n",
      "0      401  Q0  FBIS4-18182        1          3.59032  ok8amxc\n",
      "1      401  Q0  FBIS3-18916        2          3.44936  ok8amxc\n",
      "2      401  Q0  FBIS3-18833        3          3.40886  ok8amxc\n",
      "3      401  Q0  FBIS3-39117        4          3.25332  ok8amxc\n",
      "4      401  Q0  FBIS3-17077        5          3.15430  ok8amxc\n",
      "Processing file: D:\\VSCODE PROJECT\\IR\\cleaned_dataset\\cleaned_input.pir9Aa1.txt\n",
      "   topicId  Q0        docId  ranking  similarityScore   system\n",
      "0      401  Q0   FBIS4-9582        1           4.1810  pir9Aa1\n",
      "1      401  Q0  FBIS4-31715        2           4.0127  pir9Aa1\n",
      "2      401  Q0  FT942-15501        3           3.4143  pir9Aa1\n",
      "3      401  Q0   FBIS3-4201        4           3.3311  pir9Aa1\n",
      "4      401  Q0  FBIS4-18182        5           3.3238  pir9Aa1\n",
      "Processing file: D:\\VSCODE PROJECT\\IR\\cleaned_dataset\\cleaned_input.plt8ah2.txt\n",
      "   topicId  Q0        docId  ranking  similarityScore   system\n",
      "0      401  Q0   FBIS4-9582        1        13.814581  plt8ah2\n",
      "1      401  Q0  FT932-10861        2        13.342205  plt8ah2\n",
      "2      401  Q0  FBIS4-18182        3        12.389992  plt8ah2\n",
      "3      401  Q0   FBIS3-9104        4        12.071641  plt8ah2\n",
      "4      401  Q0  FT941-15167        5        11.571873  plt8ah2\n",
      "Processing file: D:\\VSCODE PROJECT\\IR\\cleaned_dataset\\cleaned_input.ric8dpn.txt\n",
      "   topicId  Q0          docId  ranking  similarityScore   system\n",
      "0      401  Q0  LA052590-0090        1         0.518393  ric8dpn\n",
      "1      401  Q0    FBIS3-19951        2         0.447785  ric8dpn\n",
      "2      401  Q0    FBIS3-59436        3         0.439529  ric8dpn\n",
      "3      401  Q0    FBIS4-68774        4         0.434339  ric8dpn\n",
      "4      401  Q0     FBIS4-9582        5         0.424880  ric8dpn\n",
      "Processing file: D:\\VSCODE PROJECT\\IR\\cleaned_dataset\\cleaned_input.UB99T.txt\n",
      "   topicId  Q0        docId  ranking  similarityScore system\n",
      "0      401  Q0  FBIS4-25684        1         177.0670  UB99T\n",
      "1      401  Q0  FBIS4-22981        2         139.5210  UB99T\n",
      "2      401  Q0  FBIS4-68773        3         120.6760  UB99T\n",
      "3      401  Q0  FBIS3-61091        4         110.9000  UB99T\n",
      "4      401  Q0   FT941-3931        5          85.2391  UB99T\n",
      "   topicId  P@10  AP@10         system\n",
      "0      401   0.9    1.0  cleaned_input\n",
      "1      402   0.9    1.0  cleaned_input\n",
      "2      403   0.9    1.0  cleaned_input\n",
      "3      404   0.9    1.0  cleaned_input\n",
      "4      405   0.9    1.0  cleaned_input\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'D:\\\\VSCODE PROJECT\\\\IR\\\\scores'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 77\u001b[0m\n\u001b[0;32m     75\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mVSCODE PROJECT\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mIR\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m final_results\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m---> 77\u001b[0m     final_results\u001b[38;5;241m.\u001b[39mto_csv(output_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32md:\\USER\\anaconda\\Lib\\site-packages\\pandas\\core\\generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3891\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3893\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3894\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3895\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3899\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3900\u001b[0m )\n\u001b[1;32m-> 3902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[0;32m   3903\u001b[0m     path_or_buf,\n\u001b[0;32m   3904\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   3905\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   3906\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   3907\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   3908\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3909\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[0;32m   3910\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   3911\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3912\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   3913\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3914\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[0;32m   3915\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   3916\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[0;32m   3917\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[0;32m   3918\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3919\u001b[0m )\n",
      "File \u001b[1;32md:\\USER\\anaconda\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1152\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1134\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1135\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1151\u001b[0m )\n\u001b[1;32m-> 1152\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1155\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32md:\\USER\\anaconda\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:247\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    250\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    251\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,\n\u001b[0;32m    252\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[0;32m    253\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[0;32m    254\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    257\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    258\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    264\u001b[0m     )\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32md:\\USER\\anaconda\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'D:\\\\VSCODE PROJECT\\\\IR\\\\scores'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to your dataset directory\n",
    "data_dir = 'D:\\VSCODE PROJECT\\IR\\cleaned_dataset'\n",
    "\n",
    "# Get the list of files in the directory\n",
    "files = [os.path.join(data_dir, file) for file in os.listdir(data_dir) if file.endswith('.txt')]\n",
    "\n",
    "# Define a threshold for similarityScore to determine relevance\n",
    "similarity_threshold = 0.5  # Adjust this value as needed\n",
    "\n",
    "# Define the function to calculate P@10 and AP@10\n",
    "def calculate_p10_ap10(df):\n",
    "    # Filter top 10 documents for each topic\n",
    "    top_10_docs = df[df['ranking'] < 10]\n",
    "    \n",
    "    # Calculate P@10 for each topic\n",
    "    p_at_10 = top_10_docs.groupby('topicId')['relevance'].apply(lambda x: x.sum() / 10)\n",
    "    \n",
    "    # Calculate AP@10 for each topic\n",
    "    def average_precision_at_10(group):\n",
    "        relevant = group['relevance'].values\n",
    "        precisions = [relevant[:i+1].sum() / (i+1) for i in range(len(relevant))]\n",
    "        return sum(precisions) / min(len(relevant), 10)\n",
    "    \n",
    "    ap_at_10 = top_10_docs.groupby('topicId').apply(average_precision_at_10)\n",
    "    \n",
    "    return p_at_10, ap_at_10\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Process each file\n",
    "for file in files:\n",
    "    try:\n",
    "        # Read the dataset\n",
    "        df = pd.read_csv(file, delimiter='\\t', names=['topicId', 'Q0', 'docId', 'ranking', 'similarityScore', 'system'])\n",
    "        \n",
    "        # Debug: Print the first few rows of the dataframe\n",
    "        print(f\"Processing file: {file}\")\n",
    "        print(df.head())\n",
    "        \n",
    "        # Ensure ranking is sorted\n",
    "        df = df.sort_values(by=['topicId', 'ranking'])\n",
    "        \n",
    "        # Create the 'relevance' column based on the similarity threshold\n",
    "        df['relevance'] = (df['similarityScore'] > similarity_threshold).astype(int)\n",
    "        \n",
    "        # Calculate P@10 and AP@10\n",
    "        p_at_10, ap_at_10 = calculate_p10_ap10(df)\n",
    "        \n",
    "        # Append the results with the system name\n",
    "        system_name = os.path.basename(file).split('.')[0]\n",
    "        result_df = pd.DataFrame({\n",
    "            'topicId': p_at_10.index,\n",
    "            'P@10': p_at_10.values,\n",
    "            'AP@10': ap_at_10.values,\n",
    "            'system': system_name\n",
    "        })\n",
    "        \n",
    "        results.append(result_df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "# Concatenate all results into a single DataFrame\n",
    "if results:\n",
    "    final_results = pd.concat(results, ignore_index=True)\n",
    "    # Debug: Print the final results\n",
    "    print(final_results.head())\n",
    "else:\n",
    "    print(\"No valid data found to concatenate.\")\n",
    "\n",
    "# Save the final results to a file\n",
    "output_path = 'D:\\VSCODE PROJECT\\IR\\scores'\n",
    "if not final_results.empty:\n",
    "    final_results.to_csv(output_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
