{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADkI38YfsCp2",
        "outputId": "a07e96bc-717a-46bc-8c95-0b0be8aee46a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       topicId identifier        docId  ranking  similarityScore systemName\n",
            "0          401         Q0  FBIS4-18182        0         3.590320    ok8amxc\n",
            "1          401         Q0  FBIS3-18916        1         3.449360    ok8amxc\n",
            "2          401         Q0  FBIS3-18833        2         3.408860    ok8amxc\n",
            "3          401         Q0  FBIS3-39117        3         3.253320    ok8amxc\n",
            "4          401         Q0  FBIS3-17077        4         3.154300    ok8amxc\n",
            "...        ...        ...          ...      ...              ...        ...\n",
            "49995      450         Q0  FBIS3-33693      995         0.855519    ok8amxc\n",
            "49996      450         Q0   FT933-6130      996         0.855423    ok8amxc\n",
            "49997      450         Q0  FBIS4-35729      997         0.855387    ok8amxc\n",
            "49998      450         Q0  FBIS3-34652      998         0.854756    ok8amxc\n",
            "49999      450         Q0  FT944-16013      999         0.854586    ok8amxc\n",
            "\n",
            "[50000 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the path to your QREL file\n",
        "data_path = 'D:\\VSCODE PROJECT\\IR\\dataset\\input.ok8amxc'\n",
        "\n",
        "# Define column names for the DataFrame\n",
        "column_names = ['topicId', 'identifier', 'docId', 'ranking', 'similarityScore', 'systemName']\n",
        "\n",
        "# Read the QREL file into a DataFrame\n",
        "df = pd.read_csv(data_path, sep='\\t', header=None, names=column_names)\n",
        "\n",
        "# Display the first few rows of the DataFrame to verify\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTAGu_723plw",
        "outputId": "bb5dd09c-2a18-444b-a17a-0cfbefed5641"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking has duplicates within each topicId: False\n",
            "Ranking is in ascending order within each topicId: True\n",
            "SimilarityScore is in descending order within each topicId: True\n"
          ]
        }
      ],
      "source": [
        "# Check for duplicates in 'Ranking' within each 'topicId' group\n",
        "has_duplicates = df.groupby('topicId')['ranking'].apply(lambda x: x.duplicated()).any()\n",
        "\n",
        "# Check if 'Ranking' is in ascending order within each 'topicId' group\n",
        "is_ascending_ranking = df.groupby('topicId')['ranking'].apply(lambda x: x.is_monotonic_increasing).all()\n",
        "\n",
        "# Check if 'SimilarityScore' is in descending order within each 'topicId' group\n",
        "is_descending_similarity = df.groupby('topicId')['similarityScore'].apply(lambda x: x.is_monotonic_decreasing).all()\n",
        "\n",
        "# Print the results\n",
        "print(\"Ranking has duplicates within each topicId:\", has_duplicates)\n",
        "print(\"Ranking is in ascending order within each topicId:\", is_ascending_ranking)\n",
        "print(\"SimilarityScore is in descending order within each topicId:\", is_descending_similarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2sIvnyChnc6h"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "topicId\n",
            "401    1000\n",
            "402    1000\n",
            "403    1000\n",
            "404    1000\n",
            "405    1000\n",
            "406    1000\n",
            "407    1000\n",
            "408    1000\n",
            "409    1000\n",
            "410    1000\n",
            "411    1000\n",
            "412    1000\n",
            "413    1000\n",
            "414    1000\n",
            "415    1000\n",
            "416    1000\n",
            "417    1000\n",
            "418    1000\n",
            "419    1000\n",
            "420    1000\n",
            "421    1000\n",
            "422    1000\n",
            "423    1000\n",
            "424    1000\n",
            "425    1000\n",
            "426    1000\n",
            "427    1000\n",
            "428    1000\n",
            "429    1000\n",
            "430    1000\n",
            "431    1000\n",
            "432    1000\n",
            "433    1000\n",
            "434    1000\n",
            "435    1000\n",
            "436    1000\n",
            "437    1000\n",
            "438    1000\n",
            "439    1000\n",
            "440    1000\n",
            "441    1000\n",
            "442    1000\n",
            "443    1000\n",
            "444    1000\n",
            "445    1000\n",
            "446    1000\n",
            "447    1000\n",
            "448    1000\n",
            "449    1000\n",
            "450    1000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Count the number of rows per topicid\n",
        "topicId_counts = df['topicId'].value_counts().sort_index()\n",
        "print(topicId_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data type of each column: \n",
            "topicId              int64\n",
            "identifier          object\n",
            "docId               object\n",
            "ranking              int64\n",
            "similarityScore    float64\n",
            "systemName          object\n",
            "dtype: object\n",
            "Count of null values in each column: \n",
            "topicId            0\n",
            "identifier         0\n",
            "docId              0\n",
            "ranking            0\n",
            "similarityScore    0\n",
            "systemName         0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check data types of all columns\n",
        "print(\"Data type of each column: \")\n",
        "print(df.dtypes)\n",
        "\n",
        "# Check null value\n",
        "print( \"Count of null values in each column: \")\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6O_4sK1_TTjy",
        "outputId": "76df67d5-006f-4e93-f85b-e71bd8d06bf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Rank in ascending order starting from 0 per topicid:\n",
            "topicId\n",
            "401    True\n",
            "402    True\n",
            "403    True\n",
            "404    True\n",
            "405    True\n",
            "406    True\n",
            "407    True\n",
            "408    True\n",
            "409    True\n",
            "410    True\n",
            "411    True\n",
            "412    True\n",
            "413    True\n",
            "414    True\n",
            "415    True\n",
            "416    True\n",
            "417    True\n",
            "418    True\n",
            "419    True\n",
            "420    True\n",
            "421    True\n",
            "422    True\n",
            "423    True\n",
            "424    True\n",
            "425    True\n",
            "426    True\n",
            "427    True\n",
            "428    True\n",
            "429    True\n",
            "430    True\n",
            "431    True\n",
            "432    True\n",
            "433    True\n",
            "434    True\n",
            "435    True\n",
            "436    True\n",
            "437    True\n",
            "438    True\n",
            "439    True\n",
            "440    True\n",
            "441    True\n",
            "442    True\n",
            "443    True\n",
            "444    True\n",
            "445    True\n",
            "446    True\n",
            "447    True\n",
            "448    True\n",
            "449    True\n",
            "450    True\n",
            "dtype: bool\n"
          ]
        }
      ],
      "source": [
        "# Function to check if the rank starts from 0 and is in ascending order\n",
        "def is_rank_ascending_from_zero(group):\n",
        "    ranks = group['ranking'].values\n",
        "    return (ranks == range(len(ranks))).all()\n",
        "\n",
        "# Group by topicid and check the rank order\n",
        "rank_ascending_from_zero = df.groupby('topicId').apply(is_rank_ascending_from_zero)\n",
        "print(\"\\nRank in ascending order starting from 0 per topicid:\")\n",
        "print(rank_ascending_from_zero)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2odqSmITYq7",
        "outputId": "b407cc74-231f-459a-943c-64316c09d04d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Similarity score in descending order per topicid:\n",
            "topicId\n",
            "401    True\n",
            "402    True\n",
            "403    True\n",
            "404    True\n",
            "405    True\n",
            "406    True\n",
            "407    True\n",
            "408    True\n",
            "409    True\n",
            "410    True\n",
            "411    True\n",
            "412    True\n",
            "413    True\n",
            "414    True\n",
            "415    True\n",
            "416    True\n",
            "417    True\n",
            "418    True\n",
            "419    True\n",
            "420    True\n",
            "421    True\n",
            "422    True\n",
            "423    True\n",
            "424    True\n",
            "425    True\n",
            "426    True\n",
            "427    True\n",
            "428    True\n",
            "429    True\n",
            "430    True\n",
            "431    True\n",
            "432    True\n",
            "433    True\n",
            "434    True\n",
            "435    True\n",
            "436    True\n",
            "437    True\n",
            "438    True\n",
            "439    True\n",
            "440    True\n",
            "441    True\n",
            "442    True\n",
            "443    True\n",
            "444    True\n",
            "445    True\n",
            "446    True\n",
            "447    True\n",
            "448    True\n",
            "449    True\n",
            "450    True\n",
            "Name: similarityScore, dtype: bool\n"
          ]
        }
      ],
      "source": [
        "# Function to check if a series is in descending order\n",
        "def is_descending(series):\n",
        "    return series.is_monotonic_decreasing\n",
        "\n",
        "# Check if similarityscore is in descending order for each topicid\n",
        "similarity_descending = df.groupby('topicId')['similarityScore'].apply(is_descending)\n",
        "print(\"\\nSimilarity score in descending order per topicid:\")\n",
        "print(similarity_descending)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmehvOGCTfGh",
        "outputId": "9639caed-2e39-418a-8c0c-8aee00b5a97b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       topicId identifier        docId  ranking  similarityScore systemName\n",
            "0          401         Q0  FBIS4-18182        1         3.590320    ok8amxc\n",
            "1          401         Q0  FBIS3-18916        2         3.449360    ok8amxc\n",
            "2          401         Q0  FBIS3-18833        3         3.408860    ok8amxc\n",
            "3          401         Q0  FBIS3-39117        4         3.253320    ok8amxc\n",
            "4          401         Q0  FBIS3-17077        5         3.154300    ok8amxc\n",
            "...        ...        ...          ...      ...              ...        ...\n",
            "49995      450         Q0  FBIS3-33693      996         0.855519    ok8amxc\n",
            "49996      450         Q0   FT933-6130      997         0.855423    ok8amxc\n",
            "49997      450         Q0  FBIS4-35729      998         0.855387    ok8amxc\n",
            "49998      450         Q0  FBIS3-34652      999         0.854756    ok8amxc\n",
            "49999      450         Q0  FT944-16013     1000         0.854586    ok8amxc\n",
            "\n",
            "[50000 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "# Reassign the rank within each topicid group\n",
        "df['ranking'] = df.groupby('topicId').cumcount() + 1\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7dHPnbZDSLp_"
      },
      "outputs": [],
      "source": [
        "# Save the cleaned DataFrame back to a file\n",
        "save_path = \"D:\\VSCODE PROJECT\\IR\\cleaned_dataset\\cleaned_input.ok8amxc.txt\"\n",
        "\n",
        "df.to_csv(save_path, sep=\"\\t\", header=False, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxhuA-3C4_0V",
        "outputId": "1c52085b-e65d-4287-df78-3d556de7ecc9"
      },
      "outputs": [],
      "source": [
        "# # Sort the DataFrame by 'topicId' and 'SimilarityScore' in descending order\n",
        "# df_sorted = df.sort_values(by=['topicId', 'similarityScore'], ascending=[True, False])\n",
        "\n",
        "# # Calculate the expected ranking based on sorted 'SimilarityScore'\n",
        "# df_sorted['ExpectedRanking'] = df_sorted.groupby('topicId').cumcount()\n",
        "\n",
        "# # Check if 'Ranking' aligns with 'ExpectedRanking'\n",
        "# is_aligned = (df_sorted['ranking'] == df_sorted['ExpectedRanking']).all()\n",
        "\n",
        "# # Print the result\n",
        "# print(\"SimilarityScore aligns with Ranking:\", is_aligned)\n",
        "# print(df_sorted)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a function to calculate P@10 and AP@10 using average similarity score as the threshold\n",
        "def calculate_p10_ap10(df):\n",
        "    results = []\n",
        "    \n",
        "    for topic_id, group in df.groupby('topicId'):\n",
        "        min_similarity = group['similarityScore'].min()\n",
        "        max_similarity = group['similarityScore'].max()\n",
        "        average_similarity = (min_similarity + max_similarity) / 2\n",
        "        \n",
        "        # Create the 'relevance' column based on the average similarity score\n",
        "        group['relevance'] = (group['similarityScore'] > average_similarity).astype(int)\n",
        "        \n",
        "        # Filter top 10 documents for the current topic\n",
        "        top_10_docs = group[group['ranking'] < 10]\n",
        "        \n",
        "        # Calculate P@10 for the current topic\n",
        "        p_at_10 = top_10_docs['relevance'].sum() / 10\n",
        "        \n",
        "        # Calculate AP@10 for the current topic\n",
        "        def average_precision_at_10(group):\n",
        "            relevant = group['relevance'].values\n",
        "            precisions = [relevant[:i+1].sum() / (i+1) for i in range(len(relevant))]\n",
        "            return sum(precisions) / min(len(relevant), 10)\n",
        "        \n",
        "        ap_at_10 = average_precision_at_10(top_10_docs)\n",
        "        \n",
        "        results.append({'topicId': topic_id, 'P@10': p_at_10, 'AP@10': ap_at_10})\n",
        "    \n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Initialize a list to store the final results for all systems\n",
        "final_results = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    topicId  P@10     AP@10\n",
            "0       401   0.9  1.000000\n",
            "1       402   0.9  1.000000\n",
            "2       403   0.9  1.000000\n",
            "3       404   0.9  1.000000\n",
            "4       405   0.9  1.000000\n",
            "5       406   0.8  0.987654\n",
            "6       407   0.9  1.000000\n",
            "7       408   0.9  1.000000\n",
            "8       409   0.9  1.000000\n",
            "9       410   0.9  1.000000\n",
            "10      411   0.5  0.858686\n",
            "11      412   0.9  1.000000\n",
            "12      413   0.9  1.000000\n",
            "13      414   0.9  1.000000\n",
            "14      415   0.9  1.000000\n",
            "15      416   0.9  1.000000\n",
            "16      417   0.9  1.000000\n",
            "17      418   0.4  0.775838\n",
            "18      419   0.9  1.000000\n",
            "19      420   0.9  1.000000\n",
            "20      421   0.9  1.000000\n",
            "21      422   0.7  0.961420\n",
            "22      423   0.9  1.000000\n",
            "23      424   0.9  1.000000\n",
            "24      425   0.9  1.000000\n",
            "25      426   0.9  1.000000\n",
            "26      427   0.9  1.000000\n",
            "27      428   0.9  1.000000\n",
            "28      429   0.9  1.000000\n",
            "29      430   0.9  1.000000\n",
            "30      431   0.6  0.919312\n",
            "31      432   0.9  1.000000\n",
            "32      433   0.3  0.665212\n",
            "33      434   0.9  1.000000\n",
            "34      435   0.9  1.000000\n",
            "35      436   0.9  1.000000\n",
            "36      437   0.9  1.000000\n",
            "37      438   0.9  1.000000\n",
            "38      439   0.9  1.000000\n",
            "39      440   0.9  1.000000\n",
            "40      441   0.8  0.987654\n",
            "41      442   0.9  1.000000\n",
            "42      443   0.9  1.000000\n",
            "43      444   0.9  1.000000\n",
            "44      445   0.9  1.000000\n",
            "45      446   0.9  1.000000\n",
            "46      447   0.9  1.000000\n",
            "47      448   0.9  1.000000\n",
            "48      449   0.9  1.000000\n",
            "49      450   0.9  1.000000\n"
          ]
        }
      ],
      "source": [
        "results_df = calculate_p10_ap10(df)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize a list to store all similarity scores\n",
        "all_similarity_scores = []\n",
        "\n",
        "# Load all data and collect similarity scores\n",
        "data_frames = []\n",
        "data_frames.append(df)\n",
        "all_similarity_scores.extend(df['similarityScore'].values)\n",
        "\n",
        "# Calculate global min, max, and average similarity scores\n",
        "global_min_similarity = min(all_similarity_scores)\n",
        "global_max_similarity = max(all_similarity_scores)\n",
        "global_avg_similarity = (global_min_similarity + global_max_similarity) / 2\n",
        "\n",
        "# Define a function to calculate P@10 and AP@10 using the global similarity score threshold\n",
        "def calculate_p10_ap10_global(df, threshold):\n",
        "    # Create the 'relevance' column based on the global average similarity score\n",
        "    df['relevance'] = (df['similarityScore'] > threshold).astype(int)\n",
        "    \n",
        "    results = []\n",
        "    \n",
        "    for topic_id, group in df.groupby('topicId'):\n",
        "        # Filter top 10 documents for the current topic\n",
        "        top_10_docs = group[group['ranking'] <= 10]\n",
        "        \n",
        "        # Calculate P@10 for the current topic\n",
        "        p_at_10 = top_10_docs['relevance'].sum() / 10\n",
        "        \n",
        "        # Calculate AP@10 for the current topic\n",
        "        def average_precision_at_10(group):\n",
        "            relevant = group['relevance'].values\n",
        "            precisions = [relevant[:i+1].sum() / (i+1) for i in range(len(relevant))]\n",
        "            return sum(precisions) / min(len(relevant), 10)\n",
        "        \n",
        "        ap_at_10 = average_precision_at_10(top_10_docs)\n",
        "        \n",
        "        results.append({'topicId': topic_id, 'P@10': p_at_10, 'AP@10': ap_at_10})\n",
        "    \n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Initialize a list to store the final results for all systems\n",
        "final_results = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    topicId  P@10     AP@10\n",
            "0       401   0.0  0.000000\n",
            "1       402   0.0  0.000000\n",
            "2       403   1.0  1.000000\n",
            "3       404   0.0  0.000000\n",
            "4       405   1.0  1.000000\n",
            "5       406   0.3  0.628690\n",
            "6       407   0.2  0.485794\n",
            "7       408   0.5  0.822817\n",
            "8       409   0.6  0.887381\n",
            "9       410   0.8  0.968889\n",
            "10      411   0.8  0.968889\n",
            "11      412   0.0  0.000000\n",
            "12      413   0.0  0.000000\n",
            "13      414   0.0  0.000000\n",
            "14      415   0.9  0.990000\n",
            "15      416   0.2  0.485794\n",
            "16      417   0.0  0.000000\n",
            "17      418   0.4  0.738254\n",
            "18      419   0.1  0.292897\n",
            "19      420   0.2  0.485794\n",
            "20      421   0.0  0.000000\n",
            "21      422   0.1  0.292897\n",
            "22      423   0.3  0.628690\n",
            "23      424   0.4  0.738254\n",
            "24      425   0.2  0.485794\n",
            "25      426   0.0  0.000000\n",
            "26      427   1.0  1.000000\n",
            "27      428   0.0  0.000000\n",
            "28      429   0.5  0.822817\n",
            "29      430   1.0  1.000000\n",
            "30      431   0.1  0.292897\n",
            "31      432   0.0  0.000000\n",
            "32      433   0.1  0.292897\n",
            "33      434   0.0  0.000000\n",
            "34      435   0.0  0.000000\n",
            "35      436   0.0  0.000000\n",
            "36      437   0.0  0.000000\n",
            "37      438   0.0  0.000000\n",
            "38      439   0.0  0.000000\n",
            "39      440   0.0  0.000000\n",
            "40      441   0.4  0.738254\n",
            "41      442   0.0  0.000000\n",
            "42      443   0.0  0.000000\n",
            "43      444   0.6  0.887381\n",
            "44      445   0.8  0.968889\n",
            "45      446   0.0  0.000000\n",
            "46      447   0.1  0.292897\n",
            "47      448   0.0  0.000000\n",
            "48      449   0.4  0.738254\n",
            "49      450   0.0  0.000000\n"
          ]
        }
      ],
      "source": [
        "results_df = calculate_p10_ap10_global(df, global_avg_similarity)\n",
        "print(results_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
